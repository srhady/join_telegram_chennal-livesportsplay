# প্রয়োজনীয় লাইব্রেরি ইম্পোর্ট করা হচ্ছে
import time
import datetime
from urllib.parse import urljoin, quote

# Selenium লাইব্রেরি ইম্পোর্ট করা হচ্ছে
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# টার্গেট ওয়েবসাইটের URL
WEBSITE_URL = "https://bingsport.watch/" 

# প্লেলিস্ট ফাইলের নাম
PLAYLIST_FILE = "playlist.m3u"

# হেডারগুলো এখানে সংজ্ঞায়িত করা হয়েছে
USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'
REFERER = WEBSITE_URL

def get_stream_links():
    """
    এই ফাংশনটি Selenium ব্যবহার করে bingsport.watch থেকে স্ট্রিম লিঙ্ক সংগ্রহ করে।
    এটি জাভাস্ক্রিপ্ট রেন্ডার হওয়ার পর লিঙ্ক খুঁজে বের করে।
    """
    stream_links = set()
    
    # --- Selenium সেটআপ ---
    print("Setting up Selenium Chrome driver...")
    chrome_options = Options()
    chrome_options.add_argument("--headless")  # ব্রাউজার না দেখিয়ে ব্যাকগ্রাউন্ডে চলবে
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument(f"user-agent={USER_AGENT}") # ইউজার এজেন্ট সেট করা

    driver = webdriver.Chrome(options=chrome_options)
    
    try:
        print(f"Loading homepage: {WEBSITE_URL}")
        driver.get(WEBSITE_URL)
        
        # পেজটি পুরোপুরি লোড হওয়ার জন্য অপেক্ষা করা হচ্ছে (সর্বোচ্চ ৩০ সেকেন্ড)
        # আমরা লাইভ ম্যাচের কন্টেইনারটি লোড হওয়ার জন্য অপেক্ষা করব
        wait = WebDriverWait(driver, 30)
        # ওয়েবসাইটের গঠন অনুযায়ী, লাইভ ম্যাচগুলো 'match-list-content' ক্লাসের মধ্যে থাকে
        wait.until(EC.presence_of_element_located((By.CLASS_NAME, "match-list-content")))
        print("Homepage loaded successfully.")
        
        # এখন পেজের সোর্স থেকে লিঙ্ক খোঁজা হবে
        page_source = driver.page_source
        
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(page_source, 'html.parser')
        
        # লাইভ ম্যাচের লিঙ্কগুলো খুঁজে বের করা
        live_matches_container = soup.find('div', class_='match-list-content')
        if not live_matches_container:
            print("Could not find the live matches container.")
            return []

        match_links = set()
        for link_tag in live_matches_container.find_all('a', href=True):
            href = link_tag.get('href')
            if href and 'live-streaming' in href:
                 match_links.add(urljoin(WEBSITE_URL, href))

        if not match_links:
            print("No live match links found inside the container.")
            return []
            
        print(f"Found {len(match_links)} match pages. Fetching stream iframes...")

        for match_link in match_links:
            try:
                print(f"-> Visiting match page: {match_link}")
                driver.get(match_link)
                # iframe লোড হওয়ার জন্য অপেক্ষা
                wait.until(EC.presence_of_element_located((By.TAG_NAME, "iframe")))
                iframe = driver.find_element(By.TAG_NAME, "iframe")
                src = iframe.get_attribute('src')
                if src:
                    stream_links.add(src)
                    print(f"   Found stream link: {src}")
            except Exception as e:
                print(f"   Could not process match page {match_link}. Error: {e}")

    finally:
        print("Closing the driver.")
        driver.quit()
        
    return list(stream_links)

def create_playlist(links):
    """
    এই ফাংশনটি লিঙ্কগুলো ব্যবহার করে একটি .m3u প্লেলিস্ট ফাইল তৈরি করে।
    """
    if not links:
        with open(PLAYLIST_FILE, "w", encoding="utf-8") as f:
            f.write("#EXTM3U\n# No live streams found at the moment.\n")
        return

    with open(PLAYLIST_FILE, "w", encoding="utf-8") as f:
        f.write("#EXTM3U\n")
        f.write(f"# Autogenerated on: {datetime.datetime.now().isoformat()}\n")
        f.write(f"# Total Streams: {len(links)}\n\n")
        
        for i, link in enumerate(links):
            try:
                stream_name = link.split('/')[2].replace('www.', '')
            except:
                stream_name = f"Stream {i+1}"
            
            encoded_user_agent = quote(USER_AGENT)
            formatted_link = f"{link}|User-Agent={encoded_user_agent}&Referer={REFERER}"
            
            f.write(f"#EXTINF:-1 tvg-id=\"\" tvg-name=\"{stream_name}\" group-title=\"Live\",{stream_name}\n")
            f.write(f"{formatted_link}\n")
    
    print(f"Playlist '{PLAYLIST_FILE}' was updated successfully with {len(links)} streams.")

if __name__ == "__main__":
    print("Starting Selenium-based scraper...")
    final_links = get_stream_links()
    create_playlist(final_links)
    print("Scraping process finished.")

