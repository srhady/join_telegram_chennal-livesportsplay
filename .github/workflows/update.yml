name: Auto Update TV Links

on:
  schedule:
    - cron: '*/15 * * * *'
  workflow_dispatch:

jobs:
  update-links:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write  # এই লাইনটি অত্যন্ত গুরুত্বপূর্ণ
    
    steps:
    - uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}  # অটোমেটিক টোকেন ব্যবহার

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: pip install requests beautifulsoup4

    - name: Scrape and update links
      run: |
        cat << 'EOF' > scraper.py
        import requests
        from bs4 import BeautifulSoup
        from datetime import datetime

        url = "https://www.bdixtv24.xyz"
        try:
            response = requests.get(url, timeout=10)
            soup = BeautifulSoup(response.text, "html.parser")
            links = []
            
            for a in soup.find_all("a", href=True):
                if "stream" in a["href"].lower():
                    link = a["href"] if a["href"].startswith("http") else f"{url}{a['href']}"
                    title = a.text.strip() or f"Channel {len(links)+1}"
                    links.append(f"- [{title}]({link})")

            with open("TV_Links.md", "w", encoding="utf-8") as f:
                f.write("# লাইভ টিভি লিংকস\n\n")
                f.write(f"**আপডেট:** {datetime.now().strftime('%d-%m-%Y %H:%M:%S')}\n\n")
                f.write("\n".join(links))
        except Exception as e:
            print(f"Error: {e}")
        EOF

        python scraper.py

    - name: Commit changes
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        git add TV_Links.md
        git commit -m "Auto-update TV links [$(date +'%d-%m-%Y %H:%M')]"
        git push
